{"categories":[{"title":"go","uri":"https://etoeto623.github.io/categories/go/"},{"title":"教程","uri":"https://etoeto623.github.io/categories/%E6%95%99%E7%A8%8B/"}],"posts":[{"content":"本文主要介绍MySQL在执行sql时，优化器是怎么选择索引的，涉及到的知识点有：\n 优化器怎么统计数据 影响索引选择的因素有哪些 优化器选错索引时怎么办  0、实验环境 本文实验的准备数据如下 数据库表t\nCREATE TABLE`t`( `id`int(11) NOT NULL, `a`int(11) DEFAULT NULL, `b`int(11) DEFAULT NULL, PRIMARY KEY(`id`), KEY `a` (`a`), KEY `b` (`b`) )ENGINE=InnoDB;  数据使用存储过程初始化\ndelimiter;; create procedure idata() begin declare i int; set i=1; while(i\u0026lt;=100000) do insert into t values(i,i,i); set i=i+1; end while; end;; delimiter; call idata();  1、优化器怎么统计数据 1、1、索引信息查看 使用show index命令可以查看索引的信息，如下：\nshow index in t;  结果如下：\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | +-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ | t | 0 | PRIMARY | 1 | id | A | 100129 | NULL | NULL | | BTREE | | | | t | 1 | a | 1 | a | A | 100129 | NULL | NULL | YES | BTREE | | | | t | 1 | b | 1 | b | A | 100129 | NULL | NULL | YES | BTREE | | | +-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+  其中，Cardinality表示索引的基数，即索引不同值的个数，数值越大表示索引的值越分散 在explain时，会提示索引扫描的行数，这个行数信息是一个大致的数据。\n1、2、索引信息统计过程 MySQL通过采样的方式来统计索引的信息，具体的流程是：\n 抽取索引的N个内存页 统计索引页中的不同值，得到这些页面的平均不同值个数 将平均值乘以索引页数，得到这个索引的基数  1、3、统计信息更新  自动触发 统计信息也不是不变的，当变更的行数超过1/M时，会自动触发 手动更新 使用analyze table t命令可以手动触发  在MySQL中，有两种存储索引统计的方式，可以通过设置参数innodb_stats_persistent的值来选择：\n 设置为on的时候，表示统计信息会持久化存储。这时，默认的N是20，M是10。 设置为off的时候，表示统计信息只存储在内存中。这时，默认的N是8，M是16。  2、索引异常的处理 优化器会综合各方面因素来决定选择什么索引：\n 索引扫描行数 随机IO次数 是否设计排序 \u0026hellip; 异常解决方法： 使用force index强制使用索引 使用analyze table t刷新统计信息 增加额外条件引导MySQL使用正确索引  ","id":0,"section":"post","summary":"本文主要介绍MySQL在执行sql时，优化器是怎么选择索引的，涉及到的知识点有： 优化器怎么统计数据 影响索引选择的因素有哪些 优化器选错索引时怎","tags":["MySQL"],"title":"MySQL的索引统计和选择","uri":"https://etoeto623.github.io/post/mysql%E7%9A%84%E7%B4%A2%E5%BC%95%E7%BB%9F%E8%AE%A1%E5%92%8C%E9%80%89%E6%8B%A9/","year":"2022"},{"content":" 这个帖子就是用来记录一些常用的资源网站导航\n    网站名 类型 网址     书享家 电子书 http://shuxiangjia.cn/   学吧导航 自学 https://www.xue8nav.com/   科塔学术 学术 https://site.sciping.com/   HiPPTer ppt资源 http://www.hippter.com/   阿猫阿狗导航 工具 https://dh.woshipm.com/   创造狮 工具 http://chuangzaoshi.com/index   199it 大数据导航 http://hao.199it.com/   打假导航 国家部门网站 http://www.dajiadaohang.com/   zero to hero languages 语言学习 https://www.zerotohero.ca   wikiHow 百科 https://zh.wikihow.com   编程导航 编程 www.code-nav.cn   小木虫 理工科 http://muchong.com/bbs/   电子发烧友 电子 http://www.elecfans.com/   生物医学搜索及工具导航 生物 https://bio-lin-187cad-1302119316.tcloudbaseapp.com/   医学导航 医学 http://www.meddir.cn/    参考地址：https://www.bilibili.com/video/BV1TN411d7FL\n","id":1,"section":"post","summary":"这个帖子就是用来记录一些常用的资源网站导航 网站名 类型 网址 书享家 电子书 http://shuxiangjia.cn/ 学吧导航 自学 https://www.xue8nav.com/ 科塔学术 学术 https://site.sciping.com/ HiPPTer ppt资源 http://www.hippter.com/ 阿猫阿狗导航 工具 https://dh.woshipm.com/ 创造狮 工具","tags":["资源"],"title":"资源收集","uri":"https://etoeto623.github.io/post/resource-collect/","year":"2021"},{"content":"微服务的优缺点 优点  服务独立部署 服务快速启动 更适合敏捷开发 专人维护专门的服务 服务可动态扩容 代码复用  缺点  分布式事务 分布式部署，调用复杂性高 测试的难度提升 运维的难度提升  Spring Cloud简介  Spring Cloud是一整套微服务的治理框架，包含服务治理、服务发现、服务熔断、负载均衡、数据监控\n spring cloud相关模块    模块 作用     eureka 服务注册   feign 服务调用   hystrix 服务熔断   config 分布式配置管理   ribbon 基于客户端的负载均衡   zuul 服务网关，提供路由转发、请求过滤等功能   slueth 服务跟踪   stream 消息驱动的微服务应用框架   bus 消息总线    ","id":2,"section":"post","summary":"微服务的优缺点 优点 服务独立部署 服务快速启动 更适合敏捷开发 专人维护专门的服务 服务可动态扩容 代码复用 缺点 分布式事务 分布式部署，调用复杂性高 测试的","tags":["微服务","spring cloud"],"title":"Spring Cloud入门教程","uri":"https://etoeto623.github.io/post/spring-cloud-introduce/","year":"2021"},{"content":"codesource是公司的一个源代码搜索平台，这里面有公司一些项目的源代码，可以在网页上进行查看。为了更方便的查看源代码，希望将源代码拉取到本地，因此写了一个简单的爬虫来爬去源代码\n爬虫的基本信息如下：\n 使用requests模块进行http请求 使用beautifulsoup4加lxml进行网页解析  爬虫的代码如下：\nimport requests import sys import os from functools import reduce from bs4 import BeautifulSoup import time RAW_BASE = 'http://codesearch.pajk-ent.com/source/raw/' XREF_BASE = 'http://codesearch.pajk-ent.com/source/xref/' def doCrawl(): args = sys.argv if len(args) != 2 : print(\u0026quot;wrong argument\u0026quot;) exit(1) # root url is passed by command line param, project name can retrieve from url root_url = args[1] requestPage(root_url) def isFileUrl(url): ''' judge if the url points to a file ''' return not url.endswith('/') def getFilePathFromUrl(url): isFile = isFileUrl(url) url = url.replace(XREF_BASE, '').replace(RAW_BASE, '') folders = list(filter(lambda str: len(str) \u0026gt; 0, url.split('/'))) if isFile : return folders[:-1], folders[-1:][0] return folders, '' def mkdirIfNotExist(dir_arr): def isDirExist(dir): return os.path.exists(dir) path = '' for dir in dir_arr: path = path + dir + \u0026quot;/\u0026quot; if not isDirExist(path): os.mkdir(path) def saveFile(folders, fileName, content): filePath = reduce(lambda a,b:a+'/'+b, folders) + '/' + fileName file = open(filePath, mode='w+') file.write(content) file.flush() file.close() count = 0 prePage = XREF_BASE headers = { 'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36', 'Host': 'codesearch.pajk-ent.com' } def requestPage(url): print('prepare to crawl: ' + url) ''' the main entry point to crawl page ''' fileUrl = isFileUrl(url) if fileUrl : # make sure visit file with raw format url = url.replace(XREF_BASE, RAW_BASE) else: url = url.replace(RAW_BASE, XREF_BASE) global headers global prePage realHeaders = headers realHeaders['Referer'] = prePage.replace(RAW_BASE, XREF_BASE) prePage = url resp = requests.get(url, headers) if resp.status_code != 200: return if fileUrl: # save file folders, fileName = getFilePathFromUrl(url) mkdirIfNotExist(folders) saveFile(folders, fileName, resp.text) time.sleep(0.5) # global count # if count \u0026gt; 2: # exit(1) # count = count + 1 else: # recursive call requestPage urls = extractUrls(url, resp.text) for u in urls: time.sleep(0.3) requestPage(u) def extractUrls(base_url, text): soup = BeautifulSoup(text, 'lxml') dirList = soup.select('#dirlist\u0026gt;tbody\u0026gt;tr') def _findUrl(d): links = d.select('td')[1].select('a') if len(links) == 0: return '' link = links[0] href = link.attrs['href'] if href == '..': return '' return base_url+href return list(filter(lambda s:len(s)\u0026gt;0, map(_findUrl, dirList))) if __name__ == '__main__': doCrawl()  ","id":3,"section":"post","summary":"codesource是公司的一个源代码搜索平台，这里面有公司一些项目的源代码，可以在网页上进行查看。为了更方便的查看源代码，希望将源代码拉取","tags":["爬虫"],"title":"codesource的代码源码爬取","uri":"https://etoeto623.github.io/post/codesource-crawl/","year":"2021"},{"content":"package main import ( \u0026quot;fmt\u0026quot; \u0026quot;math/rand\u0026quot; \u0026quot;os\u0026quot; \u0026quot;sort\u0026quot; \u0026quot;strconv\u0026quot; \u0026quot;time\u0026quot; ) func main(){ args := os.Args if len(args) != 3 { fmt.Println(\u0026quot;wrong argument\u0026quot;) return } amount, err := strconv.ParseInt(args[1], 10, 32) if nil != err { fmt.Println(\u0026quot;wrong argument: amount\u0026quot;) return } total, err := strconv.ParseInt(args[2], 10, 32) if nil != err { fmt.Println(\u0026quot;wrong argument: total\u0026quot;) } fmt.Printf(\u0026quot;amount:%d, total:%d\\n\u0026quot;, amount, total) maxRand := int(amount * 100) points := []int{} r := rand.New(rand.NewSource(time.Now().Unix())) for { if int64(len(points)) \u0026gt;= total-1{ break } randN := r.Intn(maxRand-1) + 1 if !contains(points, randN){ points = append(points, randN) } } sort.Ints(points) pre := 0 packs := []float32{} for idx:=0; idx \u0026lt; len(points); idx++ { packs = append(packs, float32(points[idx] - pre)/100) pre = points[idx] } packs = append(packs, float32(maxRand-pre)/100) fmt.Println(packs) } func contains(arr []int, num int) bool { for _,v := range arr { if v == num { return true } } return false }  ","id":4,"section":"post","summary":"package main import ( \u0026quot;fmt\u0026quot; \u0026quot;math/rand\u0026quot; \u0026quot;os\u0026quot; \u0026quot;sort\u0026quot; \u0026quot;strconv\u0026quot; \u0026quot;time\u0026quot; ) func main(){ args := os.Args if len(args) != 3 { fmt.Println(\u0026quot;wrong argument\u0026quot;) return } amount, err := strconv.ParseInt(args[1], 10, 32) if nil != err { fmt.Println(\u0026quot;wrong argument: amount\u0026quot;) return } total, err := strconv.ParseInt(args[2], 10, 32) if nil != err { fmt.Println(\u0026quot;wrong argument: total\u0026quot;) } fmt.Printf(\u0026quot;amount:%d, total:%d\\n\u0026quot;, amount, total) maxRand := int(amount * 100) points := []int{} r :=","tags":["红包"],"title":"go语言实现抢红包","uri":"https://etoeto623.github.io/post/go-red-pack/","year":"2021"},{"content":" grpc是谷歌推出的一套基于protobuf的跨语言rpc调用框架，使用protobuf协议进行信息编码，使用HTTP/2进行通信\n 环境准备 安装protobuf osx上使用homebrew安装protobuf如下：\nbrew install protobuf  安装protoc-gen-go 使用homebrew安装如下：\nbrew install protoc-gen-go  编写grpc程序 定义proto文件 定义hello.proto文件如下：\nsyntax = \u0026quot;proto3\u0026quot;; package main; message String { string value = 1; } service HelloService { rpc Hello (String) returns (String); }  根据proto文件生成go文件 执行如下命令：\nprotoc --go_out=plugins=grpc:. hello.proto  ","id":5,"section":"post","summary":"grpc是谷歌推出的一套基于protobuf的跨语言rpc调用框架，使用protobuf协议进行信息编码，使用HTTP/2进行通信 环境准备 安","tags":["go","grpc"],"title":"go中使用grpc","uri":"https://etoeto623.github.io/post/go-with-grpc/","year":"2021"},{"content":"go的内建原生rpc是通过服务端启动tcp服务，监听tcp请求，然后根据请求的服务名称和参数来实现远程服务调用的，相关的包为net/rpc\nrpc服务定义 rpcDefine.go，代码如下：\npackage rpcdemo type HelloService struct {} func (p *HelloService) Hello(request string, reply *string) error { *reply = \u0026quot;hello rpc: \u0026quot; + request return nil }  rpc服务提供者 rpcServer.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;go-demo/rpcdemo\u0026quot; \u0026quot;net\u0026quot; \u0026quot;net/rpc\u0026quot; ) func main() { // 注册服务 rpc.RegisterName(\u0026quot;HelloService\u0026quot;, new(rpcdemo.HelloService)) // 开启服务监听 listener, e := net.Listen(\u0026quot;tcp\u0026quot;, \u0026quot;:1234\u0026quot;) if nil != e { fmt.Println(\u0026quot;fatal error:\u0026quot;, e.Error()) return } conn, e := listener.Accept() if nil != e { fmt.Println(\u0026quot;accept error:\u0026quot;, e.Error()) return } fmt.Println(\u0026quot;server prepared to serve rpc call\u0026quot;) rpc.ServeConn(conn) }  rpc服务调用者 rpcClient.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;net/rpc\u0026quot; ) func main() { // 连接rpc服务 client, e := rpc.Dial(\u0026quot;tcp\u0026quot;, \u0026quot;localhost:1234\u0026quot;) if nil != e { fmt.Println(\u0026quot;dial fatal error:\u0026quot;, e.Error()) return } var reply string // 传参调用 e = client.Call(\u0026quot;HelloService.Hello\u0026quot;, \u0026quot;Hello\u0026quot;, \u0026amp;reply) if nil != e { fmt.Println(\u0026quot;rpc call fatal error:\u0026quot;, e.Error()) return } fmt.Println(\u0026quot;rpc response:\u0026quot;, reply) }  ","id":6,"section":"post","summary":"go的内建原生rpc是通过服务端启动tcp服务，监听tcp请求，然后根据请求的服务名称和参数来实现远程服务调用的，相关的包为net/rpc r","tags":["rpc"],"title":"go内建的基本rpc框架","uri":"https://etoeto623.github.io/post/go-builtin-rpc/","year":"2021"},{"content":"用途 本工具可以实现将大文件切割为指定大小的小文件块，以及将若干小文件块合并为大文件\n##使用方法\n切割文件 file_slice split block_size source_path target_path  其中：\n block_size 整数，表示小文件块的大小，单位MB source_path 源文件的路径 target_path 切割后的小文件的基础路径  合并文件 file_slice merge blocks_path file_type  其中\n blocks_path 文件块的基础路径 file_type 生成文件的文件类型  源码 package main import ( \u0026quot;bufio\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;os\u0026quot; \u0026quot;path/filepath\u0026quot; \u0026quot;strconv\u0026quot; \u0026quot;strings\u0026quot; ) func main(){ args := os.Args if len(args) \u0026lt; 2{ log(\u0026quot;wrong argument\u0026quot;) os.Exit(1) } switch args[1] { case \u0026quot;split\u0026quot;: handleSplit(args[2:]) case \u0026quot;merge\u0026quot;: handMerge(args[2:]) default: log(\u0026quot;wrong argument [mode]\u0026quot;) } } func handleSplit(args[]string){ if len(args) != 3 { log(\u0026quot;wrong split argument\u0026quot;) return } // size in MB size, e := strconv.ParseInt(args[0], 10, 10) if nil != e{ log(\u0026quot;wrong split size: \u0026quot; + args[0]) return } // source file path and target file prefix source, target := args[1], args[2] // read source file data, e := ioutil.ReadFile(source) if nil != e { log(\u0026quot;read source file error: \u0026quot; + e.Error()) return } start, step := int64(0), int64(size*1024*1024) idx := 1 filelen := int64(len(data)) for{ if start \u0026gt;= filelen{ break } end := start + step if end \u0026gt; filelen { end = filelen } targetPath := fmt.Sprintf(\u0026quot;%s%d.part\u0026quot;, target, idx) e := ioutil.WriteFile(targetPath, data[start:end], os.FileMode(0644)) if nil != e { log(\u0026quot;write partition file error: \u0026quot; + e.Error()) break } start = end idx++ } } func handMerge(args[]string){ if len(args)!=2 { log(\u0026quot;wrong merge argument\u0026quot;) return } partPath := args[0] dirPath := filepath.Dir(partPath) partNames := []string{} filepath.Walk(dirPath, func(path string, info os.FileInfo, err error) error { if strings.HasSuffix(path, \u0026quot;.part\u0026quot;) { name := filepath.Base(path) partNames = append(partNames, strings.Replace(name, \u0026quot;.part\u0026quot;, \u0026quot;\u0026quot;, 1)) } return nil }) // part file count fileCount := int64(len(partNames)) countStr := strconv.FormatInt(fileCount, 10) var fileName string for _, name := range partNames { if strings.HasSuffix(name, countStr) { fileName = name[:len(name)-len(countStr)] break } } if len(fileName) == 0 { return } targetPath := fmt.Sprintf(\u0026quot;%s/%s.%s\u0026quot;, dirPath, fileName, args[1]) mergeFile, err := os.OpenFile(targetPath, os.O_WRONLY | os.O_CREATE | os.O_EXCL, os.FileMode(0644)) if nil != err { log(\u0026quot;create merged file error: \u0026quot; + err.Error()) return } defer mergeFile.Close() writer := bufio.NewWriter(mergeFile) for i := int64(1); i \u0026lt;= fileCount; i++ { partFile := fmt.Sprintf(\u0026quot;%s/%s%s.part\u0026quot;, dirPath, fileName, strconv.FormatInt(i, 10)) partData, e := ioutil.ReadFile(partFile) if nil != e { log(\u0026quot;read partition file error: \u0026quot; + e.Error()) return } writer.Write(partData) } writer.Flush() } func log (msg interface{}){ fmt.Println(msg) }  ","id":7,"section":"post","summary":"用途 本工具可以实现将大文件切割为指定大小的小文件块，以及将若干小文件块合并为大文件 ##使用方法 切割文件 file_slice split block_size source_path target_path 其中： block_size 整数，表示小文件块的","tags":["go","文件处理"],"title":"go语言实现大文件分割与合并","uri":"https://etoeto623.github.io/post/go-file-slice/","year":"2021"},{"content":"git提交时自动生成模版msg #!/usr/bin/env groovy import static java.lang.System.exit import static java.lang.System.getenv import groovy.json.JsonSlurper import groovy.json.JsonBuilder import java.util.LinkedHashMap if(null == args || args.length == 0){ println \u0026quot;参数错误\u0026quot; exit(1) } if('--help'.equals(args[0])){ println \u0026quot;\u0026quot;\u0026quot;Usage: gcommit commit_msg [taskId] 应用分支对应的taskId在用户home目录下的gcommit.json文件中配置\u0026quot;\u0026quot;\u0026quot; exit(0) } // 获取home目录 def getHomeDir(){ getenv \u0026quot;HOME\u0026quot; } Map\u0026lt;String, Map\u0026lt;String, String\u0026gt;\u0026gt; getConfigMap(){ def cfgStr = new File(homeDir+\u0026quot;/gcommit.json\u0026quot;).text JsonSlurper parser = new JsonSlurper(); Map\u0026lt;String, Map\u0026lt;String, Integer\u0026gt;\u0026gt; config = parser.parseText(cfgStr) return config } def taskId(String app, branch){ Map\u0026lt;String, Map\u0026lt;String, Integer\u0026gt;\u0026gt; config = configMap if(!config.containsKey(app) || !config[app].containsKey(branch)){ println \u0026quot;请先配置git分支对应的taskId\u0026quot; exit(1) } config[app][branch] } // 读取当前分支名称 def getGitBranch(){ new File(\u0026quot;.git/HEAD\u0026quot;).text.replace('ref: refs/heads/', '').trim() } // 获取应用名 def getAppName(){ 'pwd'.execute().text.split('/').last().trim() } if(args[0].equals(\u0026quot;-setTask\u0026quot;)){ // 设置taskId if(args.length \u0026lt; 2){ println \u0026quot;请指定taskId\u0026quot; exit(1) } def taskId = Integer.parseInt(args[1]) def apName = appName def branch = gitBranch Map\u0026lt;String, Map\u0026lt;String, Integer\u0026gt;\u0026gt; cfMap = configMap if(!cfMap.containsKey(apName)){ cfMap.put(apName, new LinkedHashMap\u0026lt;String, Integer\u0026gt;()); } cfMap.get(apName).put(branch, taskId) new File(homeDir+\u0026quot;/gcommit.json\u0026quot;).text = new JsonBuilder(cfMap).toPrettyString() }else{ def task = args.length \u0026gt; 1 ? args[1] : taskId(appName,gitBranch) println \u0026quot;git commit -m Desc:${args[0]} -m Type:ReqDev -m ID:$task \u0026quot;.execute().text }  推送到gerrit #!/bin/bash branch_name=\u0026quot;$1\u0026quot; if [ \u0026quot;\u0026quot; == \u0026quot;$1\u0026quot; ]; then # 没有传分支号，则获取当前分支名 branch_name=`git branch | grep \\* | cut -d ' ' -f2` fi function echo_green(){ echo -e \u0026quot;\\033[36m$1 \\033[0m\u0026quot; } echo_green ============================================= echo Starting push $branch_name to gerrit git push origin $branch_name:refs/for/$branch_name echo Push finished echo_green =============================================  jvm占用内存统计 nohup cmd \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\n#!/bin/bash function log_memo(){ pid=`jps -l | grep tj.jar | awk '{print $1}'` real_use=`ps -e -o 'pid,comm,rsz' | grep java | grep $pid | awk '{print strftime(\u0026quot;[%Y-%m-%d %H:%M:%S]\u0026quot;,systime()),$NF,$NF/1024/1024 \u0026quot;G\u0026quot;}'` jstat_use='' if(($1 % 2 == 0)); then jstat_use=`jstat -gc $pid | awk '{if(NR==2){print $3,$4,$6,$8,$10,$12}}'` fi echo $real_use $jstat_use \u0026gt;\u0026gt; memo_log_`date +%m%d`.txt } loop_times=0 while ((loop_times \u0026lt; 1200)) do log_memo $loop_times ((loop_times += 1)) sleep 3m done  记录pmap信息 #!/bin/bash function logPmap(){ pid=`jps -l | grep tj.jar | awk '{print $1}'` dateStr=`date +%m%d%H%M` pmap -x $pid | awk '{if(NR\u0026gt;2\u0026amp;\u0026amp;$3\u0026gt;60000\u0026amp;\u0026amp;$3\u0026lt;100000)print $0}' \u0026gt; /home/admin/tj/pmaplogs/`echo $dateStr`.txt ps -e -o 'pid,comm,rsz' | grep java | grep $pid | awk '{print strftime(\u0026quot;[%Y-%m-%d %H:%M:%S]\u0026quot;,systime()),$NF,$NF/1024/1024 \u0026quot;G\u0026quot;}' \u0026gt;\u0026gt; /home/admin/tj/pmaplogs/`echo $dateStr`.txt } loop_times=0 while ((loop_times \u0026lt; 200)) do logPmap ((loop_times += 1)) sleep 1h done  ","id":8,"section":"post","summary":"git提交时自动生成模版msg #!/usr/bin/env groovy import static java.lang.System.exit import static java.lang.System.getenv import groovy.json.JsonSlurper import groovy.json.JsonBuilder import java.util.LinkedHashMap if(null == args || args.length == 0){ println \u0026quot;参数错误\u0026quot; exit(1) } if('--help'.equals(args[0])){ println \u0026quot;\u0026quot;\u0026quot;Usage: gcommit commit_msg [taskId] 应用分支对应的ta","tags":["shell"],"title":"脚本收集","uri":"https://etoeto623.github.io/post/script-collect/","year":"2021"},{"content":"输入输出 通过flag包获取命令行参数 命令行参数获取可以通过os.Args，但这种方式比较原始，参数是通过一个字符串数组传递，需要自己写代码处理，还有一种方法就是通过flag包\nflag包可以获取命令行中-param=value和-param value格式的参数，如下为代码示例：\npackage main\rimport (\r\u0026quot;flag\u0026quot;\r\u0026quot;fmt\u0026quot;\r)\rfunc main() {\rname := flag.String(\u0026quot;name\u0026quot;, \u0026quot;neo\u0026quot;, \u0026quot;输入用户名\u0026quot;) // neo是默认值\rage := flag.Int(\u0026quot;age\u0026quot;, 18, \u0026quot;输入年龄\u0026quot;)\rflag.Parse()\rfmt.Println(\u0026quot;name =\u0026quot;, *name) // 这里name是指针类型，需要加*进行取值\rfmt.Println(\u0026quot;age =\u0026quot;, *age)\r}\r 生成的程序，使用-h参数可以打印出相关的帮助信息。如下：\nUsage of ./test:\r-age int\r输入年龄 (default 18)\r-name string\r输入用户名 (default \u0026quot;neo\u0026quot;)\r 参考文档  csdn\u0026ndash;万字介绍go  ","id":9,"section":"post","summary":"输入输出 通过flag包获取命令行参数 命令行参数获取可以通过os.Args，但这种方式比较原始，参数是通过一个字符串数组传递，需要自己写代码处","tags":["go"],"title":"go简介","uri":"https://etoeto623.github.io/post/go-intro/","year":"2021"},{"content":"堆排序的简介 堆排序是一种选择排序，使用了堆这种数据结构。堆就是一种完全二叉树\n核心思想就是将数组中的最大的数挑选出来，然后再将子数组的最大的数挑选出来，以此递归，知道子数组只有一个元素为止\n算法的时间复杂度为$nlog(n)$\n堆分为两种：大顶堆和小顶堆\n 大顶堆：二叉树的节点值大于其所有的子节点值。用于从小到大的排序 小顶堆：二叉树的节点值小于其所有的子节点值。用于从大到小的排序  算法实现 public class HeapSortReal { public static void main(String[] args){ int[] arr = new int[]{4,2,1,8,9,5,0,11,7,13,6}; doSort(arr); System.out.println(JSON.toJSONString(arr)); } public static void doSort(int[] arr){ makeHeap(arr, arr.length); // 构造堆结构 sort(arr, arr.length); } private static void sort(int[] arr, int len){ if(len \u0026lt;= 1){ return; } swap(arr, 0, len-1); // 将最大值(堆中的第一个元素)放到堆尾 heapify(arr, 0, len-1); // 重新整理堆 sort(arr, len-1); // 将最值提取后，再处理子数组 } private static void makeHeap(int[] arr, int len){ for (int i = Math.floorDiv(len, 2); i \u0026gt;= 0; i--) { // Math.floorDiv表示是从倒数第二层的最后一个节点开始构造 heapify(arr, i, len); } } private static void heapify(int[] arr, int idx, int len){ int left = 2*idx+1, right = 2*idx+2; // 下标为idx的节点的两个子节点 int max = idx; if(left \u0026lt; len \u0026amp;\u0026amp; arr[left] \u0026gt; arr[max]){ max = left; } if(right \u0026lt; len \u0026amp;\u0026amp; arr[right] \u0026gt; arr[max]){ max = right; } if(max != idx){ swap(arr, max, idx); // 将最大值做为父节点 heapify(arr, max, len); // 这里是为了从根节点进行重排时的递归操作 } } private static void swap(int[] arr, int idx1, int idx2){ int temp = arr[idx1]; arr[idx1] = arr[idx2]; arr[idx2] = temp; } }  提取最值后重新整理堆的逻辑是：\n 第一次初始化堆时，数据已经按层排序好了，上层的数据大于下层的数据 重新整理时，由于只替换了根节点的数据，所以子数组的最大值就在根节点和其两个子节点中 重新整理的作用就是：将最大的值移到根节点，同时将小数下层，大数上提  参考文章：\n https://www.runoob.com/w3cnote/heap-sort.html cnblogs  ","id":10,"section":"post","summary":"堆排序的简介 堆排序是一种选择排序，使用了堆这种数据结构。堆就是一种完全二叉树 核心思想就是将数组中的最大的数挑选出来，然后再将子数组的最大的数","tags":["algorithm","排序算法"],"title":"堆排序","uri":"https://etoeto623.github.io/post/heap-sort/","year":"2021"},{"content":"镜像构建简述 docker构建镜像，需要编写一个Dockerfile，指定构建的脚本，然后使用docker build命令进行构建\n需要以一个基础镜像为基础进行构建，在此镜像上，通过docker提供的一些命令来添加功能\n镜像构建示例 如下是一个docker构建的示例\n  编写Dockerfile\nmkdir mywebtest # 创建一个构建工作目录 vim Dockerfile # 编辑dockerfile  其中，Dockerfile内容如下：\nFROM openjdk:8 # 使用java8做为基础镜像 COPY ./lab-web.jar /usr/src/ # 将java web应用拷贝到java8镜像的相关目录中 WORKDIR /usr/src # 指定工作目录 CMD [\u0026quot;java\u0026quot;, \u0026quot;-jar\u0026quot;, \u0026quot;lab-web.jar\u0026quot;] # 指定docker run时执行的命令    执行构建命令\ndocker build -t mywebtest:test . # 指定镜像的名称和标签，并指定使用当前目录下的dockerfile  命令的执行结果如下：\nSending build context to Docker daemon 30.3MB Step 1/4 : FROM openjdk:8 ---\u0026gt; eca41db787bd Step 2/4 : COPY ./lab-web.jar /usr/src/ ---\u0026gt; Using cache ---\u0026gt; c1280ab6e005 Step 3/4 : WORKDIR /usr/src ---\u0026gt; Using cache ---\u0026gt; f15316e3e33e Step 4/4 : CMD [\u0026quot;java\u0026quot;, \u0026quot;-jar\u0026quot;, \u0026quot;lab-web.jar\u0026quot;] ---\u0026gt; Running in 96e58fb3087f Removing intermediate container 96e58fb3087f ---\u0026gt; c5bd3f8cd906 Successfully built c5bd3f8cd906 Successfully tagged myjavaweb:test    运行容器\ndocker run --name myjavaweb -p 8080:8080 myjavaweb:test    常用构建命令   FROM\n指定一个构建的基础镜像，一般都需要以FROM命令开始\n  COPY\n拷贝文件命令，可以将本地的文件拷贝到镜像文件系统中。格式如下：\nCOPY [--chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt;] \u0026lt;源路径1\u0026gt;... \u0026lt;目标路径\u0026gt;    ADD\n也是拷贝文件命令，和COPY不同的是，如果拷贝的是压缩文件，会自动解压到目标目录。实现同样功能的前提下，官方推荐使用COPY命令\n  WORKDIR\n指定工作目录，使用WORKDIR命令的目录，会在构建镜像的每一层都存在\n  RUN\n在go build的时候执行命令，后面接具体的shell命令，比如将代码源码拷贝到镜像中，然后执行编译命令，如下:\nRUN javac Hello.java # 在构建镜像的时候执行编辑java的命令    CMD\n也是执行命令的命令，和RUN不同的是，该命令是在docker run的时候执行，为启动的容器指定默认要运行的程序，程序运行结束，容器也就结束。CMD 指令指定的程序可被 docker run 命令行参数中指定要运行的程序所覆盖。\n如果Dockerfile中指定了多个CMD命令，仅最后一个CMD命令有效\nCMD \u0026lt;shell命令\u0026gt; CMD [\u0026quot;可执行命令\u0026quot;, \u0026quot;命令参数1\u0026quot;, \u0026quot;命令参数2\u0026quot; ...]    ENTRYPOINT\n和CMD类似，也是docker run时执行命令，不同的是：ENTRYPOINT不会被 docker run 的命令行参数指定的指令所覆盖，而且这些命令行参数会被当作参数送给 ENTRYPOINT 指令指定的程序。\n  ENV\n设置环境变量，在后续的命令中可以使用这些变量\nENV \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; ENV \u0026lt;key1\u0026gt;=\u0026lt;value1\u0026gt; \u0026lt;key2\u0026gt;=\u0026lt;value2\u0026gt;...    ARG\n构建参数，与 ENV 作用一至。不过作用域不一样。ARG 设置的环境变量仅对 Dockerfile 内有效，也就是说只有 docker build 的过程中有效，构建好的镜像内不存在此环境变量。\n构建命令 docker build 中可以用 \u0026ndash;build-arg \u0026lt;参数名\u0026gt;=\u0026lt;值\u0026gt; 来覆盖。\n  参考文章：\n https://www.runoob.com/docker/docker-dockerfile.html  ","id":11,"section":"post","summary":"镜像构建简述 docker构建镜像，需要编写一个Dockerfile，指定构建的脚本，然后使用docker build命令进行构建 需要以一个基础","tags":["docker"],"title":"构建docker镜像","uri":"https://etoeto623.github.io/post/docker-build/","year":"2021"},{"content":"修改最新提交的消息 修改最新一次提交的消息，只要一条命令即可，如下：\ngit commit --amend  然后进入交互式的修改界面，修改后提交即可\n修改历史提交的消息 如果需要修改很多个提交以前的消息，使用git commit --amend无法实现，git也没有提供相关的修改命令，这时可以结合rebase来实现，步骤如下：\n  找到需要修改的提交的父提交\ngit log    rebase到父提交\ngit rebase -i HEAD~n # 必须使用-i，进行交互式的rebase，head~n是需要修改提交的父提交 # 或如下命令 git rebase -i commitId # commitId是待修改的提交的父提交id    将需要修改的提交的pick修改为edit，并退出编辑\nedit f7f3f6d changed my name a bit # 将pick改为edit pick 310154e updated README formatting and added blame pick a5f4a0d added cat-file    使用git commit --amend来编辑提交消息\n  rebase continue\ngit rebase --continue  参考文章：git官方文档\n  ","id":12,"section":"post","summary":"修改最新提交的消息 修改最新一次提交的消息，只要一条命令即可，如下： git commit --amend 然后进入交互式的修改界面，修改后提交即可 修改历史提交的消息 如果需要修","tags":["git"],"title":"git修改提交commit消息","uri":"https://etoeto623.github.io/post/git-change-commit-msg/","year":"2021"},{"content":"redis中有五种数据类型，分别是：\n string hash set zset list  string类型 最常用的就是string类型，以key-value的方式存在内存中\n常用的命令    命令 说明 示例     set 设置key-value set name neo   get 获取值，key不存在则返回nil get name   getset 返回key的老值，同时设置新值 getset key newVal   setnx 设置key的值，如果key已存在值，则设置失败 setnx key val   incr 将key的值加1，key不存在，则值设为1，支持负数 incr key   setex key设值并指定过期时间 setex key expSec val   mset 批量设置key mset key1 v1 key2 v2   mget 批量查询key mget key1 key2    使用场景 缓存 可以对数据库或接口，进行结果的缓存，以支持高并发，降低服务器压力\n计数器 适用于高并发的计数工作，并发量大时，如果每次改变计数都修改数据库，会造成数据库压力过大\n不过需要注意处理redis宕机造成的计数丢失的问题\n共享session 将用户的session数据存在redis中，从而支持多个web应用使用统一的session\n限速 将用户的访问数据记录在redis中，并设置过期时间，用来控制用户的访问频次\n底层实现 redis底层使用简单动态字符串sds来表示字符串，在sds.h文件中定义，定义如下：\nstruct sdshdr { // 用于记录buf数组中使用的字节的数目 // 和SDS存储的字符串的长度相等 int len; // 用于记录buf数组中没有使用的字节的数目 int free; // 字节数组，用于储存字符串 char buf[]; //buf的大小等于len+free+1，其中多余的1个字节是用来存储’\\0’的。 };  内部有sds的几种定义：sdshdr5、sdshdr8、sdshdr16、sdshdr32、sdshdr64。sdshdr16定义如下：\nstruct __attribute__ ((__packed__)) sdshdr16 { uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; };  list类型 列表类型的数据，在一个key中保存一个列表\n常用的命令    命令 说明 示例     lpush/rpush 从左边/右边向列表中添加元素 lpush key v1 [v2 ...]   lpop/rpop 从左边/右边从列表中弹出元素 rpop key   lpushx/rpushx 向已存在的列表中添加元素 rpushx key v1 [v2 ...]   lindex 用索引从列表中取值，从左开始，下标0开始 lindex key 3   llen 获取列表的长度 llen key    使用场景 消息队列 可以通过push和pop，实现FIFO的队列或者FILO的栈结构，实现FIFO类似于golang中的channel，只是不会有阻塞。队列消费者可以通过循环不停的从队列中取值\n该队列只能实现1对1，要实现1对多，可以使用redis的发布/订阅模式，即subscribe/publish\n列表数据 可以用list来保存列表数据，比如商品列表\n底层实现 list底层使用ziplist和linkedlist来存储数据\n当列表对象同时满足以下两个条件时，列表对象使用ziplist进行存储，否则用linkedlist存储：\n 列表对象保存的所有字符串元素的长度小于64字节 列表对象保存的元素数量小于512个。  set类型 set是一个无序且不重复的字符串数据集合，每个集合最多可以存储2^32-1个元素\n常用的命令    命令 说明 示例     sadd 向集合中添加元素 sadd key v1 [v2 ...]   spop 从集合中随机弹出元素 spop key [count]   smembers 获取集合中的所有元素 smembers key   sismember 判断集合中是否有某个元素 sismember key val   smove 将元素从一个集合移动到另一个集合 smove fkey tkey val    使用场景 元素去重 比如，不允许重复点赞，则可以将所有已点赞的数据存储在set中，进行去重\n随机展示 将数据放入一个集合中，然后随机从中取一部分元素进行展示，造成数据挺多的假象，比如商品推荐\n黑/白名单 判断数据在集合中/不在集合中，才允许/禁止进行某些操作\n底层实现 底层有两种实现方式，当value是整数值时，且数据量不大时使用intset来存储，其他情况都是用字典dict来存储。\nintset数据结构的定义在intset.h中，如下：\ntypedef struct intset { uint32_t encoding; uint32_t length; int8_t contents[]; } intset;  encoding如下：\n/* Note that these encodings are ordered, so: * INTSET_ENC_INT16 \u0026lt; INTSET_ENC_INT32 \u0026lt; INTSET_ENC_INT64. */ #define INTSET_ENC_INT16 (sizeof(int16_t)) #define INTSET_ENC_INT32 (sizeof(int32_t)) #define INTSET_ENC_INT64 (sizeof(int64_t))  zset类型 zset是有序的集合，在set的基础上，对key的值加上了一个分值属性，按分值进行排序\n常用命令    命令 说明 示例     zadd 向集合中添加元素 zadd key score1 val1 [score2 val2 ...]   zrange 按索引取指定范围的元素 zrange key startIdx endIdx [withscores]   zrangebyscore 按分值取指定范围的元素 zrangebyscore key start end [withscore][limit offset count]   zincrby 给指定元素增加分值 zincrby key incrNum member   zrem 从集合中移除若干元素 zrem key member1 [member2 ...]   zcount 获取集合中执行分数范围的数量（包含两端） zcount key min max    使用场景 排行榜 利用根据分数排序的特性，实现排行榜\n缓存数据分页 使用zrangebyscore可以进行缓存的分页查询\n延时队列 将时间戳作为score，队列中的数据进行排序，循环取集合中的第一个值，值的时间戳大于当前时间戳，则表示可以执行了\n滑动窗口限流 将用户的访问记录按时间戳为分值存储在集合中，使用zcount可以获取用户在指定时间段内的访问次数，以此来进行限流\n底层实现 底层有两种数据结构实现：ziplist和skiplist\nzipList：满足以下两个条件\n [score,value]键值对数量少于128个； 每个元素的长度小于64字节；  skipList：不满足以上两个条件时使用跳表、组合了hash和skipList\n hash用来存储value到score的映射，这样就可以在O(1)时间内找到value对应的分数； skipList按照从小到大的顺序存储分数 skipList每个元素的值都是[socre,value]对  skiplist的结构定义在server.h中，如下：\ntypedef struct zskiplistNode { sds ele; double score; struct zskiplistNode *backward; struct zskiplistLevel { struct zskiplistNode *forward; unsigned long span; } level[]; } zskiplistNode; typedef struct zskiplist { struct zskiplistNode *header, *tail; unsigned long length; int level; } zskiplist;  hash类型 hash就是存储key-value格式的数据\n常用命令    命令 说明 示例     hset 设置值 hset key field value   hget 查询值 hget key field   hdel 删除field hdel key field1 [field2 ...]   hgetall 获取key的所有field hgetall key   hmset 批量设置值 hmset key f1 v1 [f2 v2 ...]   hexists 判断是否存在field hexists key field    使用场景 结构数据缓存 hash结构很好的符合了对象数据的结构，可以使用hash来缓存结构数据，避免使用json string缓存造成的json序列/反序列化\n属性集合的存储 比如广告位系统缓存的存储，将广告位code作为key，用户id作为field，这样可以很好的将广告位进行统一的过期\n底层实现 底层有两种数据结构的实现：ziplist和dict\n当hash的v值较小时，使用ziplist，较大时使用dict\ndict的定义在dict.h中，如下：\ntypedef struct dictEntry { void *key; union { void *val; uint64_t u64; int64_t s64; double d; } v; struct dictEntry *next; } dictEntry; typedef struct dictht { dictEntry **table; unsigned long size; unsigned long sizemask; unsigned long used; } dictht; typedef struct dict { dictType *type; void *privdata; dictht ht[2]; // 存储数据的地方，使用开链法解决冲突 long rehashidx; /* rehashing not in progress if rehashidx == -1 */ unsigned long iterators; /* number of iterators currently running */ } dict;  ","id":13,"section":"post","summary":"redis中有五种数据类型，分别是： string hash set zset list string类型 最常用的就是string类型，以key-value的方式存在内存中 常用的命令 命","tags":null,"title":"redis的五种类型","uri":"https://etoeto623.github.io/post/redis-types/","year":"2021"},{"content":"简介 channel是go中的一个重要的概念，可以看成是一个数据的管道，数据发送端和接收端可以通过channel进行数据的传递。\nGo并发的核心哲学是不要通过共享内存进行通信; 相反，通过沟通分享记忆。\nchannel的操作符是\u0026lt;-，如下表示channel的发送和接收操作：\nch \u0026lt;- 1. // 向ch中发送数据 \u0026lt;-ch; // 从ch中取数据，也可以写成 \u0026lt;- ch  其实这个很好记，很形象，箭头的方向就是数据的流动方向\nchannel的操作 创建channel 使用make来创建channel，如下：\nch := make(chan int) // 创建一个channel，用来传递int型的数据 cacheable_ch := make(chan float64, 100) // 创建一个带有缓存的channel，向其中写数据不会阻塞，除非缓存已满  创建channel需要指定数据类型，如果向channel中写其他类型的数据，会报错\nchannel有如下几种类型：\n  读写channel\nmake(chan int) // 默认的就是读写channel    只读channel\nmake(\u0026lt;-chan int) // 只读的channel，如果向里面写数据会报错 // invalid operation: readch \u0026lt;- 3 (send to receive-only type \u0026lt;-chan int)    只写channel\nmake(chan\u0026lt;- int) // 只写channel // invalid operation: \u0026lt;-readch (receive from send-only type chan\u0026lt;- int)    关闭channel 使用close来关闭channel，如下：\nch := make(chan int) defer close(ch) // 关闭channel，defer（延迟执行）表示它后面的语句在代码块执行完毕后执行 go func(){ch \u0026lt;- 1+2}() fmt.Println(\u0026lt;-ch)  需要注意的是，向关闭的channel写数据会报错，但从关闭的channel中仍可以读数据，待channel中的数据读取完毕后，获取的指为0，且读取不会阻塞\nch := make(chan int, 3) ch \u0026lt;- 1+2 close(ch) // 关闭channel fmt.Println(\u0026lt;-ch) // 可以正常取出数据 v,ok := \u0026lt;-ch // 取出的为0，ok=false fmt.Printf(\u0026quot;value is %d, status is %b\u0026quot;, v, ok) ch \u0026lt;- 5 // panic: send on closed channel  select 操作 select是专门针对channel的一个操作，类似于switch，从select的众多case分支中，随机选择一个可用的channel，执行后续操作\n选中的那个case分支的channel会执行一次取数操作\nch1, ch2 := make(chan int, 3), make(chan int, 3) for i := 0; i \u0026lt; 3 ; i++ { ch1 \u0026lt;- i ch2 \u0026lt;- 9-i } select { case \u0026lt;-ch1: fmt.Printf(\u0026quot;ch1 select is: %d\\n\u0026quot;, \u0026lt;-ch1) case \u0026lt;-ch2: fmt.Printf(\u0026quot;ch2 select is: %d\\n\u0026quot;, \u0026lt;-ch2) } fmt.Printf(\u0026quot;ch1 after is: %d\\n\u0026quot;, \u0026lt;-ch1) fmt.Printf(\u0026quot;ch2 after is: %d\\n\u0026quot;, \u0026lt;-ch2) /** 如上代码可能打印 ch1 select is: 1 ch1 after is: 2 ch2 after is: 9 或者 ch2 select is: 8 ch1 after is: 0 ch2 after is: 7 */  channel中的超时机制 结合select和time.After，可以时间channel的读取超时机制，如下：\nch := make(chan string) select { case v:=\u0026lt;-ch: fmt.Printf(\u0026quot;channel v is: %s\\n\u0026quot;, v) case \u0026lt;-time.After(time.Second * 3): // 超时3秒 fmt.Println(\u0026quot;channel read timeout\u0026quot;) }  channel的一些应用 在goroutine中同步 ch := make(chan bool) defer close(ch) go func(){ time.Sleep(time.Second * 5) // 耗时的任务 ch \u0026lt;- true }() \u0026lt;-ch // 等待任务完成 fmt.Println(\u0026quot;goroutine is done\u0026quot;)  定时器 time包中的NewTimer使用channel来实现定时功能，如下：\nfmt.Println(time.Now().Format(\u0026quot;2006-01-02 15:04:05\u0026quot;)) timer := time.NewTimer(time.Second * 3) \u0026lt;-timer.C // timer.C是一个channel fmt.Printf(\u0026quot;finished in %s\\n\u0026quot;, time.Now().Format(\u0026quot;2006-01-02 15:04:05\u0026quot;))  如上可以使用更简单的time.After来实现\nt := \u0026lt;-time.After(time.Second * 3) fmt.Println(t)  NewTicker可以生成一个定时脉冲，如下：\nticker := time.NewTicker(time.Second * 2) for t := range ticker.C { // 使用range可以不断从channel中取值 fmt.Println(t) // 间隔两秒打印一次 }  参考博客  go channel详解 go语言的defer go channel实现原理 go channel和select—csdn  ","id":14,"section":"post","summary":"简介 channel是go中的一个重要的概念，可以看成是一个数据的管道，数据发送端和接收端可以通过channel进行数据的传递。 Go并发的核心","tags":["golang","channel"],"title":"go中的channel","uri":"https://etoeto623.github.io/post/go-channel/","year":"2021"},{"content":"并发和并行 并发 并发是通过时间片轮转的方式，让多个任务在一个物理处理器上轮流执行，同一时间只有一个任务在执行\n并行 并行是让多个任务在多个物理处理器上执行，达到任务同时执行的目的，同一时间有多个任务在执行\n基于共享数据的并发 无并发控制 如下代码没有进行并发控制，会导致共享数据的最终结果错误\nvar ( count int32 wg sync.WaitGroup // 类似java中的CountdownLatch ) func main(){ call(inc_danger) } func call( fn func() ){ wg.Add(2) go fn() go fn() wg.Wait() fmt.Println(count) // 最终结果大概率是小于10000的 } func inc_danger(){ // 这里没有做并发控制 defer wg.Done() for i := 0; i \u0026lt; 5000; i++ { count++ } }  原子并发控制 如下使用加锁的方式来实现并发控制\nfunc inc_safe(){ defer wg.Done() for i := 0; i \u0026lt; 5000; i++ { atomic.AddInt32(\u0026amp;count, 1) // 原子操作 } }  加锁并发控制 使用sync包的Mutex可以进行加锁，如下：\nvar ( count int32 wg sync.WaitGroup ) func call( fn func() ){ wg.Add(3) go fn() go fn() go fn() wg.Wait() fmt.Println(count) } // 这里需要接受锁对象的指针 func inc_lock(lock *sync.Mutex, set map[int32]bool){ for i := 0; i \u0026lt; 5000; i++ { lock.Lock() count++ lock.Unlock() } wg.Done() } func main(){ var lock sync.Mutex // 锁对象 var set = make(map[int32]bool) // 这里\u0026amp;lock是关键，必须传锁的地址，否则多个goroutine用的就不是一个锁对象了 call(func(){inc_lock(\u0026amp;lock, set)}) }  基于channel的并发控制 由于channel有阻塞功能，可以通过channel的读写来实现并发控制，如下：\nvar ( count int32 wg sync.WaitGroup ) func main(){ ch := make(chan bool, 1) // 这里需要执行channel的缓冲大小为1 call(func(){inc_channel(ch)}) } func call( fn func() ){ wg.Add(3) go fn() go fn() go fn() wg.Wait() fmt.Println(count) } func inc_channel(ch chan bool){ defer wg.Done() for i := 0; i \u0026lt; 5000; i++ { ch\u0026lt;-true // 由于channel缓冲大小为1，所以这里写数据就相当于获取锁 count++ \u0026lt;-ch // 相当于释放锁 } }  参考文章  go语言并发—C语言中文网  ","id":15,"section":"post","summary":"并发和并行 并发 并发是通过时间片轮转的方式，让多个任务在一个物理处理器上轮流执行，同一时间只有一个任务在执行 并行 并行是让多个任务在多个物理处理","tags":["golang","并发"],"title":"go语言的并发","uri":"https://etoeto623.github.io/post/go-concurrent/","year":"2021"},{"content":" 问题描述  使用fastjson进行对象序列化(JSON.toJSONString)时，如果需要格式化的对象中存在对象的循环引用，即A-\u0026gt;B、A-\u0026gt;C、B→C，则默认生成的json字符串会存在$引用符号，如下：\n{ \u0026#34;jbs\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;bean1\u0026#34; }, { \u0026#34;jbs\u0026#34;: [ { \u0026#34;$ref\u0026#34;: \u0026#34;$.jbs[0]\u0026#34; // 这里表示循环引用  } ], \u0026#34;name\u0026#34;: \u0026#34;bean2\u0026#34; } ], \u0026#34;name\u0026#34;: \u0026#34;bean3\u0026#34; }  这种格式的json字符串在后端之间用来传递数据还问题不大，如果要将这种json字符串给前端，则会出问题。\n  解决方法  深拷贝  对循环引用中公用的对象进行深拷贝\n  设置SerializerFeature  如下，在进行序列化\n    ","id":16,"section":"post","summary":"问题描述 使用fastjson进行对象序列化(JSON.toJSONString)时，如果需要格式化的对象中存在对象的循环引用，即A-\u0026gt;","tags":["fastjson"],"title":"fastjson的循环引用序列化","uri":"https://etoeto623.github.io/post/fastjson-circularref/","year":"2021"},{"content":" 代码目录  代码目录如下： asynchttp\n   – AsyncClient   – AsyncHttpMain   – GenericHandler   – HttpHandler    参考地址\n  代码示例  AsyncClient  import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; import io.netty.handler.codec.http.DefaultFullHttpRequest; import io.netty.handler.codec.http.HttpMethod; import io.netty.handler.codec.http.HttpRequestEncoder; import io.netty.handler.codec.http.HttpResponseDecoder; import io.netty.handler.codec.http.HttpVersion; import io.netty.util.concurrent.EventExecutorGroup; import org.apache.commons.lang3.time.DateFormatUtils; import java.net.URI; import java.util.Date; import java.util.Map; public class AsyncClient { final static EventExecutorGroup executor = new NioEventLoopGroup(5); final static EventLoopGroup g; final static Bootstrap b; static { g = new NioEventLoopGroup(); b = new Bootstrap(); b.group(g) .channel(NioSocketChannel.class) .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 5000); } private static Object LOCK = new Object(); public static boolean doGet(String url, Map\u0026lt;String, String\u0026gt; head, final HttpHandler handler){ try{ System.out.println(\u0026#34;---prepare to get: \u0026#34; + url); URI uri = new URI(url); String domain = uri.getHost(); int port = uri.getPort() \u0026lt; 0 ? 80 : uri.getPort(); DefaultFullHttpRequest request = new DefaultFullHttpRequest(HttpVersion.HTTP_1_1, HttpMethod.GET, uri.toASCIIString()); if (head == null) { request.headers().add(\u0026#34;Host\u0026#34;, domain); request.headers().add(\u0026#34;User-Agent\u0026#34;, \u0026#34;Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:44.0) Gecko/20100101 Firefox/44.0\u0026#34;); request.headers().add(\u0026#34;Accept\u0026#34;, \u0026#34;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\u0026#34;); request.headers().add(\u0026#34;Accept-Language\u0026#34;, \u0026#34;zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3\u0026#34;); request.headers().add(\u0026#34;Connection\u0026#34;, \u0026#34;keep-alive\u0026#34;); request.headers().add(\u0026#34;Cache-Control\u0026#34;, \u0026#34;max-age=0\u0026#34;); } else { for (Map.Entry entry : head.entrySet()) { request.headers().add((String) entry.getKey(), entry.getValue()); } } ChannelInitializer\u0026lt;SocketChannel\u0026gt; channelInitializer = new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new HttpResponseDecoder()) .addLast(new HttpRequestEncoder()) .addLast(executor, new GenericHandler(handler)); } }; ChannelFuture f; synchronized (LOCK){ // 这里不进行同步的话，请求的handler会串  // 进行连接  try{ System.out.println(DateFormatUtils.format(new Date(), \u0026#34;yyyy-MM-dd HH:mm:ss SSS\u0026#34;) + \u0026#34; prepare to connect: \u0026#34; + domain); b.handler(channelInitializer); Thread.sleep(10); f = b.connect(domain, port).sync(); }catch(Exception e){ handler.error(url, e); return false; } System.out.println(DateFormatUtils.format(new Date(), \u0026#34;yyyy-MM-dd HH:mm:ss SSS\u0026#34;) + \u0026#34; connected to: \u0026#34; + domain); } f.channel().writeAndFlush(request); return true; }catch(Exception e){ e.printStackTrace(); return false; } } public static void close(){ try{ executor.shutdownGracefully(); g.shutdownGracefully(); }catch(Exception e){ e.printStackTrace(); } } }    AsyncHttpMain  import java.util.Map; import java.util.concurrent.CountDownLatch; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class AsyncHttpMain { public static void main(String[] args) throws InterruptedException { CountDownLatch latch = new CountDownLatch(3); ExecutorService executor = Executors.newCachedThreadPool(); executor.submit(()-\u0026gt;{ AsyncClient.doGet(\u0026#34;http://www.baidu.com\u0026#34;, null, new HttpHandler() { @Override public void handle(Map\u0026lt;String, String\u0026gt; headMap, String body) { System.out.println(\u0026#34;--- baidu: \u0026#34; + body); latch.countDown(); } @Override public void error(String url, Exception e) { e.printStackTrace(); latch.countDown(); } }); }); Thread.sleep(100); executor.submit(()-\u0026gt;{ String url = \u0026#34;http://srv.dev.pajkdc.com/shield/m.api?_mt=liteworkflow.processQueryToDo\u0026amp;applyer=\u0026amp;pageNo=1\u0026amp;pageSize=10\u0026amp;taskType=\u0026#34;; AsyncClient.doGet(url, null, (head,body)-\u0026gt;{ System.out.println(\u0026#34;--- dev: \u0026#34; + body); latch.countDown(); }); }); executor.submit(()-\u0026gt;{ AsyncClient.doGet(\u0026#34;http://srv.test.pajkdc.com/shield/api/cache/getValue?key=_DLK_tijian_TJ_PDF_UPLOAD_022012288000072017\u0026#34;, null, (head,body)-\u0026gt;{ System.out.println(\u0026#34;---test: \u0026#34; + body); latch.countDown(); }); }); executor.shutdown(); latch.await(); AsyncClient.close(); } }    GenericHandler  import io.netty.buffer.ByteBuf; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; import io.netty.handler.codec.http.HttpContent; import io.netty.handler.codec.http.HttpResponse; import java.util.HashMap; import java.util.Map; public class GenericHandler extends ChannelInboundHandlerAdapter { private HttpHandler httpHandler; int respLength = Integer.MAX_VALUE; Map\u0026lt;String, String\u0026gt; head = new HashMap\u0026lt;\u0026gt;(); String respContent = \u0026#34;\u0026#34;; public GenericHandler(HttpHandler httpHandler) { this.httpHandler = httpHandler; } @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { if(msg instanceof HttpResponse){ HttpResponse response = (HttpResponse) msg; for (Map.Entry entry : response.headers().entries()) { head.put((String) entry.getKey(), (String) entry.getValue()); } if (response.headers().get(\u0026#34;Content-Length\u0026#34;) != null) { respLength = Integer.parseInt(response.headers().get(\u0026#34;Content-Length\u0026#34;)); } } if(msg instanceof HttpContent){ HttpContent content = (HttpContent) msg; ByteBuf buf = content.content(); respContent += buf.toString(httpHandler.charset()); ((HttpContent) msg).release(); if (respContent.getBytes().length \u0026gt;= respLength || !buf.isReadable()) { ctx.channel().close(); httpHandler.handle(head, respContent); } } } }    HttpHandler  import io.netty.util.CharsetUtil; import java.nio.charset.Charset; import java.util.Map; public interface HttpHandler { void handle(Map\u0026lt;String, String\u0026gt; headMap, String body); default void error(String url, Exception e){ e.printStackTrace(); } default Charset charset(){ return CharsetUtil.UTF_8; } }      ","id":17,"section":"post","summary":"代码目录 代码目录如下： asynchttp – AsyncClient – AsyncHttpMain – GenericHandler – HttpHandler 参考地址 代码示例 AsyncClient import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; import io.netty.handler.codec.http.DefaultFullHttpRequest; import io.netty.handler.codec.http.HttpMethod; import io.netty.handler.codec.http.HttpRequestEncoder; import io.netty.handler.codec.http.HttpResponseDecoder; import io.netty.handler.codec.http.HttpVersion; import io.netty.util.concurrent.EventExecutorGroup; import org.apache.commons.lang3.time.DateFormatUtils; import java.net.URI; import java.util.Date; import java.util.Map; public class AsyncClient { final","tags":["netty","异步"],"title":"基于netty的异步http请求","uri":"https://etoeto623.github.io/post/netty-async-http/","year":"2021"},{"content":"总览 ubuntu中使用latex，需要用到texlive（latex核心系统）和texmaker（latex编辑器），同时需要中文支持的话，需要用xelatex命令\n安装texlive texlive的官方下载地址为：https://mirror.ctan.org/systems/texlive/tlnet/install-tl-unx.tar.gz\n该链接下载的是一个安装程序，下载后，使用sudo 命令运行安装脚本，之后会联网下载依赖，最终下载在/use/local/texlive文件夹下\n安装texmaker texmaker的官网地址为：https://www.xm1math.net/texmaker/\n支持中文 xelatex命令在/usr/local/texlive/2021/bin/x86_64-linux/下，将该目录加入到path中\n在latex文档中，使用ctexart，如下：\n\\documentclass[UTF8,a4paper]{ctexart} \\usepackage{minted, xcolor, geometry} % 使用geometry可以自由的设置页面属性 \\geometry{left=3.0cm, right=3.0cm, bottom=2cm} \\title{Common Lisp中的读取宏} \\author{neolong} \\definecolor{codebg}{rgb}{0.95,0.95,0.95} % 定义代码块背景色 \\newcommand\\codeit[1]{\\colorbox{codebg}{\\textit{#1}}} % 定义行内代码命令 \\begin{document} \\maketitle 读取器宏也许不像普通的宏一样有名，但读取器宏是创建自定义DSL的一个强大的工具，读取器宏甚至提供更大的灵活性已让允许你基于Lisp创建一整套新的语法。\\\\ 保罗格雷厄姆在他的书\\textit{On Lisp}中很好的解释了这一特点： \\end{document}  然后使用如下命令进行文档编译：\nxelatex -shell-escape lisp-read-macro.tex  ","id":18,"section":"post","summary":"总览 ubuntu中使用latex，需要用到texlive（latex核心系统）和texmaker（latex编辑器），同时需要中文支持的话，","tags":["latex"],"title":"ubuntu中安装latex","uri":"https://etoeto623.github.io/post/latex-start/","year":"2021"},{"content":" test  测试行内$y=mc^2$公式\n   名字 年龄 大小     张三 23 1 盾   李四 24 2     另一个 29 3    $$ f(x)=\\int_{-\\infty}^\\infty\\widehat f\\xi\\,e^{2\\pi i\\xi x}\\,d\\xi $$\n  ","id":19,"section":"post","summary":"test 测试行内$y=mc^2$公式 名字 年龄 大小 张三 23 1 盾 李四 24 2 另一个 29 3 $$ f(x)=\\int_{-\\infty}^\\infty\\widehat f\\xi\\,e^{2\\pi i\\xi x}\\,d\\xi $$","tags":["数学","公式","测试"],"title":"测试文档","uri":"https://etoeto623.github.io/post/pattern/","year":"2021"},{"content":" 安装 hugo  hugo 是使用 go 开发的，所以需要安装 go。go 的安装步骤参考官网\nexport PATH=$PATH:/usr/local/go/bin    下载 hugo  参考hugo github的步骤将\nmkdir $HOME/src git clone https://github.com/gohugoio/hugo.git cd hugo go install    hugo 的使用  参考hugo 中文网的使用教程\n创建站点  hugo new site /path/to/site    创建文章  hugo new about.md  hugo 支持多种格式的文档，比如 markdown、orgmode 等，具体可以参考这里\n  添加主题  cd themes git clone https://github.com/spf13/hyde.git  另外，在hugo 的主题网站可以找到更多主题\n  启动服务器  hugo server --theme=hyde --buildDrafts    部署 github  hugo --theme=hyde --baseUrl=\u0026#34;http://coderzh.github.io/\u0026#34; cd public git init git remote add origin https://github.com/coderzh/coderzh.github.io.git git add -A git commit -m \u0026#34;first commit\u0026#34; git push -u origin master      ","id":20,"section":"post","summary":"安装 hugo hugo 是使用 go 开发的，所以需要安装 go。go 的安装步骤参考官网 export PATH=$PATH:/usr/local/go/bin 下载 hugo 参考hugo github的步骤将 mkdir $HOME/src git clone https://github.com/gohugoio/hugo.git cd hugo go install hugo 的使用 参考hu","tags":["hugo","博客"],"title":"hugo 的使用","uri":"https://etoeto623.github.io/post/hugo_use/","year":"2021"},{"content":" $$\\begin{cases} a_1x+b_1y+c_1z=d_1\\\\ a_2x+b_2y+c_2z=d_2\\\\ a_3x+b_3y+c_3z=d_3\\\\ \\end{cases} $$\n","id":21,"section":"post","summary":"$$\\begin{cases} a_1x+b_1y+c_1z=d_1\\\\ a_2x+b_2y+c_2z=d_2\\\\ a_3x+b_3y+c_3z=d_3\\\\ \\end{cases} $$","tags":["math"],"title":"数学公式的使用","uri":"https://etoeto623.github.io/post/math/","year":"0001"}],"tags":[{"title":"algorithm","uri":"https://etoeto623.github.io/tags/algorithm/"},{"title":"channel","uri":"https://etoeto623.github.io/tags/channel/"},{"title":"docker","uri":"https://etoeto623.github.io/tags/docker/"},{"title":"fastjson","uri":"https://etoeto623.github.io/tags/fastjson/"},{"title":"git","uri":"https://etoeto623.github.io/tags/git/"},{"title":"go","uri":"https://etoeto623.github.io/tags/go/"},{"title":"golang","uri":"https://etoeto623.github.io/tags/golang/"},{"title":"grpc","uri":"https://etoeto623.github.io/tags/grpc/"},{"title":"hugo","uri":"https://etoeto623.github.io/tags/hugo/"},{"title":"latex","uri":"https://etoeto623.github.io/tags/latex/"},{"title":"math","uri":"https://etoeto623.github.io/tags/math/"},{"title":"MySQL","uri":"https://etoeto623.github.io/tags/mysql/"},{"title":"netty","uri":"https://etoeto623.github.io/tags/netty/"},{"title":"rpc","uri":"https://etoeto623.github.io/tags/rpc/"},{"title":"shell","uri":"https://etoeto623.github.io/tags/shell/"},{"title":"spring cloud","uri":"https://etoeto623.github.io/tags/spring-cloud/"},{"title":"公式","uri":"https://etoeto623.github.io/tags/%E5%85%AC%E5%BC%8F/"},{"title":"博客","uri":"https://etoeto623.github.io/tags/%E5%8D%9A%E5%AE%A2/"},{"title":"并发","uri":"https://etoeto623.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"title":"异步","uri":"https://etoeto623.github.io/tags/%E5%BC%82%E6%AD%A5/"},{"title":"微服务","uri":"https://etoeto623.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"title":"排序算法","uri":"https://etoeto623.github.io/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"title":"数学","uri":"https://etoeto623.github.io/tags/%E6%95%B0%E5%AD%A6/"},{"title":"文件处理","uri":"https://etoeto623.github.io/tags/%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86/"},{"title":"测试","uri":"https://etoeto623.github.io/tags/%E6%B5%8B%E8%AF%95/"},{"title":"爬虫","uri":"https://etoeto623.github.io/tags/%E7%88%AC%E8%99%AB/"},{"title":"红包","uri":"https://etoeto623.github.io/tags/%E7%BA%A2%E5%8C%85/"},{"title":"资源","uri":"https://etoeto623.github.io/tags/%E8%B5%84%E6%BA%90/"}]}